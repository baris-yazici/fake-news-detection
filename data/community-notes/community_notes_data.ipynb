{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Community Notes Data\n",
    "\n",
    "- We first filter the community notes data with only helpful and not helpful notes.\n",
    "- We then select notes that are in English.\n",
    "- Finally, we convert the data to a KTO trainer format as required by KTO Trainer, which can be seen from the following link: https://huggingface.co/docs/trl/main/en/kto_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the helpful notes from X's community notes data\n",
    "## The data we downloaded includes contributions up until 1:32 AM Â· Mar 10, 2024\n",
    "### first download the data from this link: https://twitter.com/i/communitynotes/download-data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the notes file\n",
    "notes = pd.read_csv('/Users/barisyazici/Desktop/Community Notes Data/notes-00000.tsv', delimiter='\\t')\n",
    "notes_status = pd.read_csv('/Users/barisyazici/Desktop/Community Notes Data/noteStatusHistory-00000.tsv', delimiter='\\t')\n",
    "\n",
    "# Value counts\n",
    "notes_status[\"currentStatus\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect helpful and not helpful note ids in seperate lists\n",
    "helpful_note_ids = notes_status.loc[notes_status[\"currentStatus\"] == \"CURRENTLY_RATED_HELPFUL\", \"noteId\"].to_list()\n",
    "not_helpful_note_ids = notes_status.loc[notes_status[\"currentStatus\"] == \"CURRENTLY_RATED_NOT_HELPFUL\", \"noteId\"].to_list()\n",
    "\n",
    "# Filter the original notes data based on note ids\n",
    "helpful_notes = notes[notes[\"noteId\"].isin(helpful_note_ids)]\n",
    "not_helpful_notes = notes[notes[\"noteId\"].isin(not_helpful_note_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful Notes\n",
    "\n",
    "df_helpful_notes = helpful_notes\n",
    "\n",
    "# Create the \"prompt\" column with default value\n",
    "df_helpful_notes['prompt'] = \"\"\n",
    "\n",
    "# Function to insert spaces before underscores\n",
    "def insert_spaces_underscore(column):\n",
    "    return ' '.join(word.capitalize() for word in column.split('_'))\n",
    "\n",
    "# Function to insert spaces before capital letters\n",
    "def insert_spaces_capital(column):\n",
    "    return ''.join([' ' + c if c.isupper() else c for c in column]).strip()\n",
    "\n",
    "# Iterate over each row\n",
    "for index, row in df_helpful_notes.iterrows():\n",
    "    # Adding spaces to the classification column\n",
    "    classification = insert_spaces_underscore(row['classification'])\n",
    "    misleading_columns = ['misleadingOther', 'misleadingFactualError',\n",
    "                          'misleadingManipulatedMedia', 'misleadingOutdatedInformation',\n",
    "                          'misleadingMissingImportantContext', 'misleadingUnverifiedClaimAsFact',\n",
    "                          'misleadingSatire', 'notMisleadingOther',\n",
    "                          'notMisleadingFactuallyCorrect',\n",
    "                          'notMisleadingOutdatedButNotWhenWritten', 'notMisleadingClearlySatire',\n",
    "                          'notMisleadingPersonalOpinion']\n",
    "    \n",
    "    # Find the column name with value 1\n",
    "    for column in misleading_columns:\n",
    "        if row[column] == 1:\n",
    "            misleading_column = insert_spaces_capital(column)\n",
    "            break\n",
    "\n",
    "    # Fill in the prompt column\n",
    "    prompt_text = f\"Please explain the evidence behind your choice of labeling this tweet as {classification}, to help others who see this tweet understand why it is {misleading_column}\"\n",
    "    df_helpful_notes.at[index, 'prompt'] = prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unhelpful Notes\n",
    "\n",
    "df_not_helpful_notes = not_helpful_notes\n",
    "\n",
    "# Create the \"prompt\" column with default value\n",
    "df_not_helpful_notes['prompt'] = \"\"\n",
    "\n",
    "# Function to insert spaces before underscores\n",
    "def insert_spaces_underscore(column):\n",
    "    return ' '.join(word.capitalize() for word in column.split('_'))\n",
    "\n",
    "# Function to insert spaces before capital letters\n",
    "def insert_spaces_capital(column):\n",
    "    return ''.join([' ' + c if c.isupper() else c for c in column]).strip()\n",
    "\n",
    "# Iterate over each row\n",
    "for index, row in df_not_helpful_notes.iterrows():\n",
    "    # Adding spaces to the classification column\n",
    "    classification = insert_spaces_underscore(row['classification'])\n",
    "    misleading_columns = ['misleadingOther', 'misleadingFactualError',\n",
    "                          'misleadingManipulatedMedia', 'misleadingOutdatedInformation',\n",
    "                          'misleadingMissingImportantContext', 'misleadingUnverifiedClaimAsFact',\n",
    "                          'misleadingSatire', 'notMisleadingOther',\n",
    "                          'notMisleadingFactuallyCorrect',\n",
    "                          'notMisleadingOutdatedButNotWhenWritten', 'notMisleadingClearlySatire',\n",
    "                          'notMisleadingPersonalOpinion']\n",
    "    \n",
    "    # Find the column name with value 1\n",
    "    for column in misleading_columns:\n",
    "        if row[column] == 1:\n",
    "            misleading_column = insert_spaces_capital(column)\n",
    "            break\n",
    "\n",
    "    # Fill in the prompt column\n",
    "    prompt_text = f\"Please explain the evidence behind your choice of labeling this tweet as {classification}, to help others who see this tweet understand why it is {misleading_column}\"\n",
    "    df_not_helpful_notes.at[index, 'prompt'] = prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community Notes Data to KTO Trainer Format\n",
    "\n",
    "# The data should be in the following format\n",
    "'''kto_dataset_dict = {\n",
    "    \"prompt\": [\n",
    "        \"Hey, hello\",\n",
    "        \"How are you\",\n",
    "        \"What is your name?\",\n",
    "        \"What is your name?\",\n",
    "        \"Which is the best programming language?\",\n",
    "        \"Which is the best programming language?\",\n",
    "        \"Which is the best programming language?\",\n",
    "    ],\n",
    "    \"completion\": [\n",
    "        \"hi nice to meet you\",\n",
    "        \"leave me alone\",\n",
    "        \"I don't have a name\",\n",
    "        \"My name is Mary\",\n",
    "        \"Python\",\n",
    "        \"C++\",\n",
    "        \"Java\",\n",
    "    ],\n",
    "    \"label\": [\n",
    "        True,\n",
    "        False,\n",
    "        False,\n",
    "        True,\n",
    "        True,\n",
    "        False,\n",
    "        False,\n",
    "    ]\n",
    "}'''\n",
    "\n",
    "\n",
    "import re\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(2002)\n",
    "\n",
    "# Assuming df_helpful_notes and df_not_helpful_notes are your DataFrames\n",
    "# Add a new column 'label' to indicate the label\n",
    "df_helpful_notes['label'] = True\n",
    "df_not_helpful_notes['label'] = False\n",
    "\n",
    "# Combine the DataFrames\n",
    "combined_df = pd.concat([df_helpful_notes, df_not_helpful_notes], ignore_index=True)\n",
    "\n",
    "# Shuffle the indices\n",
    "shuffled_indices = np.random.permutation(combined_df.index)\n",
    "combined_df_shuffled = combined_df.iloc[shuffled_indices]\n",
    "\n",
    "\n",
    "combined_df_shuffled = combined_df_shuffled.loc[:,[\"summary\", \"prompt\", \"label\"]]\n",
    "\n",
    "# Function to remove URLs from text\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "# Filter out rows with missing or null values in the 'summary' column\n",
    "combined_df_filtered = combined_df_shuffled.dropna(subset=['summary'])\n",
    "\n",
    "# Remove URLs from the 'summary' column\n",
    "combined_df_filtered['summary'] = combined_df_filtered['summary'].apply(lambda x: remove_urls(x) if isinstance(x, str) else None)\n",
    "\n",
    "# Filter out rows where 'summary' text is not empty\n",
    "combined_df_filtered = combined_df_filtered[combined_df_filtered['summary'].notnull() & (combined_df_filtered['summary'] != '')]\n",
    "\n",
    "# Function to detect language\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except LangDetectException as e:\n",
    "        print(f\"Error detecting language: {e}\")\n",
    "        return None\n",
    "\n",
    "# Add a new column 'language' to indicate the language of the summary\n",
    "combined_df_filtered['language'] = combined_df_filtered['summary'].apply(detect_language)\n",
    "\n",
    "# Filter out the rows where language detection was successful\n",
    "combined_df_filtered = combined_df_filtered.dropna(subset=['language'])\n",
    "\n",
    "# Filter out the English summaries\n",
    "combined_df_english = combined_df_filtered[combined_df_filtered['language'] == 'en']\n",
    "\n",
    "# Count the labels\n",
    "combined_df_english['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create kto_dataset_dict with only English summaries\n",
    "kto_dataset_dict = {\n",
    "    \"prompt\": combined_df_english['prompt'].tolist(),\n",
    "    \"completion\": combined_df_english['summary'].tolist(),\n",
    "    \"label\": combined_df_english['label'].tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Optional if you want to export the data as csv\n",
    "\n",
    "'''# Convert kto_dataset_dict to a DataFrame\n",
    "df_kto_dataset_dict = pd.DataFrame(kto_dataset_dict)\n",
    "\n",
    "# Export DataFrame to CSV file\n",
    "df_kto_dataset_dict.to_csv('/Users/barisyazici/Desktop/community_noyes_kto.csv', index=False)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
